{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50bd5daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3]), tf.float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Overview\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([[1., 2., 3.],\n",
    "                 [4., 5., 6.]])\n",
    "\n",
    "x.shape, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862a14d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ tf.transpose(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f16959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([x,x,x],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51deff35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.09003057, 0.24472848, 0.66524094],\n",
       "       [0.09003057, 0.24472848, 0.66524094]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(x,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab86126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([2, 2], dtype=int64)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(x,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e97fadee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([2, 2], dtype=int64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.backend.argmax(x,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1038a8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=21.0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "754b8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.convert_to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e872515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleModule(tf.Module):\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "    self.a_variable = tf.Variable(5.0, name=\"train_me\")\n",
    "    self.non_trainable_variable = tf.Variable(5.0, trainable=False, name=\"do_not_train_me\")\n",
    "  def __call__(self, x):\n",
    "    return self.a_variable * x + self.non_trainable_variable\n",
    "\n",
    "simple_module = SimpleModule(name=\"simple\")\n",
    "simple_module(tf.constant(5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.checkpoint.CheckpointManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b47b126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequential model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "model = keras.Sequential(\n",
    "[\n",
    "    layers.Dense(2,activation='relu',name='layer1'),\n",
    "    layers.Dense(3,activation='relu',name='layer2'),\n",
    "    layers.Dense(4,name='layer3')\n",
    "])\n",
    "\n",
    "x = tf.ones((3,3))\n",
    "y = model(x)\n",
    "\n",
    "\n",
    "# layer1 = layers.Dense(2, activation='relu',name='layer1')\n",
    "# layer2 = layers.Dense(3, activation='relu',name='layer2')\n",
    "# layer3 = layers.Dense(4, activation='relu',name='layer3')\n",
    "\n",
    "# x = tf.ones((3,3))\n",
    "# y = layer3(layer2(layer1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f6cfd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x2df60ee49a0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2df5f4b0340>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2df5f4b08b0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e07e4cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(4,)))\n",
    "model.add(layers.Dense(2,activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69027abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x2df5f4b07f0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c20add0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2,activation='relu',input_shape=(4,)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f4180c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(250, 250, 3)),\n",
    "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "feature_extractor = keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=[layer.output for layer in initial_model.layers],\n",
    ")\n",
    "\n",
    "# Call feature extractor on test input.\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a86dbf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 123, 123, 32), dtype=float32, numpy=\n",
       " array([[[[0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          ...,\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215]],\n",
       " \n",
       "         [[0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          ...,\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215]],\n",
       " \n",
       "         [[0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          ...,\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          ...,\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215]],\n",
       " \n",
       "         [[0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          ...,\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215]],\n",
       " \n",
       "         [[0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          [0.        , 0.6472995 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965215],\n",
       "          ...,\n",
       "          [0.        , 0.6472994 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965229],\n",
       "          [0.        , 0.6472994 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965229],\n",
       "          [0.        , 0.6472994 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.00965229]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 121, 121, 32), dtype=float32, numpy=\n",
       " array([[[[0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113473,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113471,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.1511347 ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.15113468,\n",
       "           0.        , 0.        ]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 119, 119, 32), dtype=float32, numpy=\n",
       " array([[[[0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750245, 0.14708298, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.03750246, 0.14708297, 0.        , ..., 0.12233609,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750244, 0.14708297, 0.        , ..., 0.12233606,\n",
       "           0.        , 0.        ],\n",
       "          [0.03750239, 0.14708298, 0.        , ..., 0.12233602,\n",
       "           0.        , 0.        ]]]], dtype=float32)>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7d81265",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'endswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      2\u001b[0m     keras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m784\u001b[39m)),\n\u001b[0;32m      3\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m      7\u001b[0m ])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Presumably you would want to first load pre-trained weights.\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Freeze all layers except the last one.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n",
      "File \u001b[1;32m~\\Desktop\\AC\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2195\u001b[0m, in \u001b[0;36mModel.load_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2190\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2191\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen calling model.load_weights, skip_mismatch can only be set to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2192\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue when by_name is True.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2194\u001b[0m filepath \u001b[38;5;241m=\u001b[39m path_to_string(filepath)\n\u001b[1;32m-> 2195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_hdf5_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   2196\u001b[0m   save_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Desktop\\AC\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2814\u001b[0m, in \u001b[0;36m_is_hdf5_filepath\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m   2813\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_hdf5_filepath\u001b[39m(filepath):\n\u001b[1;32m-> 2814\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m filepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   2815\u001b[0m           filepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'endswith'"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(784)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10),\n",
    "])\n",
    "\n",
    "# Presumably you would want to first load pre-trained weights.\n",
    "model.load_weights(...)\n",
    "\n",
    "# Freeze all layers except the last one.\n",
    "for layer in model.layers[:-1]:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Recompile and train (this will only update the weights of the last layer).\n",
    "model.compile(...)\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3de7267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.7648 - accuracy: 0.7703 - val_loss: 0.2685 - val_accuracy: 0.9203\n",
      "Epoch 2/2\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2335 - accuracy: 0.9327 - val_loss: 0.1917 - val_accuracy: 0.9448\n",
      "313/313 - 0s - loss: 0.1895 - accuracy: 0.9430\n",
      "Test loss: 0.18948808312416077\n",
      "Test accuracy: 0.9430000185966492\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b11b4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
