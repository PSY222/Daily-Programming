'''
Reference
https://www.kaggle.com/code/willkoehrsen/introduction-to-manual-feature-engineering/notebook
'''

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore)

plt.style.use('fivethirtyeight')


bureau = pd.read_csv('../input/bureau.csv')
bureau.head()

previous_loan_counts = bureau.groupby('SK_ID_CURR',as_index =False)['SK_ID_BUREAU'].count().rename(columns={'SK_ID_BUREAU':'previous_loan_counts})

previous_loan_counts.head()

train = pd.read_csv('../input/application_train.csv')
train = train.merge(previous_loan_counts,on='SK_ID_CURR',how='left')

train['previous_loan_counts] = train['previous_loan_counts].fillna(0)
train.head()


def kde_target(var_name,df):
    corr = df['target].corr(df[var_name])

    avg_rapaid = df.ix[df['TARGET'] == 0,var_name].median()
    avg_not_repaid = df.idx[df['TARGET' == 1, var_name],var_name].median()

    sns.kdeplot(df.ix[df['TARGET']==0,var_name],label='TARGET ==0')
    sns.kdeplot(df.ix[df['TARGET']==1, var_name], label = 'TARGET ==1')

    plt.xlabel(Var_name)
    plt.ylabel('Denstiy')
    plt.title('%s Distribution'%var_name)
    plt.legend()

    print('The correlation between %s and the TARGET is %0.4f'%(var_name,corr))
    print('Median value for loan that was not repaid = %0.4f'%avg_not_repaid)
    print('Median value for loan was repaid = %0.4f'%avg_repaid)

kde_target('EXT_SOURCE_3',train)
kde_target('previous_loan_counts',train)

bureau_agg = bureau.drop(columns =['SK_ID_BUREAU']).groupby('SK_ID_CURR',as_index=False).agg(['count','mean','max','min','sum']).reset_index()

bureau_agg.head()

columns = ['SK_ID_CURR']

for var in bureau_agg.columns.levels[0]:
    if var != 'SK_ID_CURR':
        for stat in bureau_agg.columns.levels[1][:-1]:
            columns.append('bureau_%s_%s'%(var,stat))

bureau_agg.columns = columns
bureau_agg.head()

train = train.merge(bureau_agg,on='SK_ID_CURR',how='left')
train.head()


new_corrs = []

for col in columns:
    cor =train['TARGET'].corr(train[col])
    new_corrs.append((col,corr))

new_corrs = sorted(new_corrs,key= lambda x" abs(x[1]),reverse = True)
new_corrs[:15]

kde_target('bureau_DAYS_CREDIT_mean',train)

def agg_numeric(df,group_var,df_name):
    for col in df:
        if col != group_var and 'SK_ID' in col:
            df = df.drop(columns = col)

    group_ids = df[group_var]
    numeric_df = df.select_dtypes('number')
    numeric_df[group_var] = group_ids

    agg= numeric_df.groupby(group_var).agg(['count','mean','max','min','sum']).reset_index()


    columns = [group_Var]

    for var in agg.columns.levels[0]:
        if var != group_var:
            for stat in agg.columns.levels[1][:-1]:
                columns.apend('%s_%s_%s'%(df_name,var,stat))

    agg.columns = columns
    return agg

def target_corrs(df):
    corrs = []

    for col in df.columns:
        print(col)
        if col != 'TARGET':
            corr = df['TARGET'].corr(df[col])
            corrs.append((col,corr))

    corrs =sorted(corrs,key = lambda x: abs(x[1]), reverse = True)
    return corrs


#dealing with categorical data

categorical = pd.get_dummies(bureau.select_dtypes('object'))
categorical['SK_ID_CURR'] = bureau['SK_ID_CURR']
categorical.head()

categorical_grouped = categorical.groupby('SK_ID_CURR').agg(['sum','mean'])
categorical_grouped.head()

categorical_grouped.columns.levels[0][:10]
categorical_grouped.columns.levels[1]

group_var = 'SK_ID_CURR'

columns = []

for var in categorical_grouped.columns.levels[0]:
    if var != group_var:
        for stat in ['count','count_norm']:
            columns.append('%s_%s' % (var,stat))

categorical_grouped.columns = columns

categorical_grouped.head()

train = train.merge(categorical_grouped, left_on = 'SK_ID_CURR',right_index = True, how = 'left)

train.head()
train.shape

train.iloc[:10,123:]

def count_categorical(df,group_var,df_name):
    categorical[group_var] = df[group_var]
    categorical = categorical.groupby(group_var).agg(['sum','mean'])
    
    column_names = []

    for  var in categorical.columns.levels[0]:
        for stat in ['count','count_norm]:
            column_names.append('%s_%s_%s' % (df_name,var,stat))

    categorical.columns = column_names

    return categorical

bureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR',df_name='bureau)
bureau_counts.head()

bureau_balance_counts = count_categorical(bureau_balance,group_var='SK_ID_BUREAU', df_name = 'bureau_balance')

bureau_balance_coutns.head()

bureau_balance)agg = agg_numeric(bureau_balance, group_var='SK_ID_BUREAU',df_name='bureau_balance')

bureau_balance_agg.head()

bureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts,right_index=True,left_on = 'SK_ID_BUREAU', how='left')

bureau_by_loan.head()

bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns=['SK_ID_BUREAU']),group_var = 'SK_ID_BUREAU', df_name='clinet')

bureau_balance_by_client.head()

import gc
gc.enable()

del train, bureau, bureau_balance, bureau_agg, bureau_agg_new, bureau_balance_agg, bureau_balance_counts, bureau_by_loan, bureau_balance_by_client, bureau_counts

gc.collect()

train = pd.read_csv('../input/application_train.csv')
bureau = pd.read_csv('../input/bureau.csv')
bureau_balance = pd.read_csv('../input/bureau_balance.csv')

bureau_counts = count_categorical(bureau,group_var='SK_ID_CURR',df_name='bureau')

bureau_counts.head()

bureau_agg = agg_numeric(bureau.drop(columns=['SK_ID_CURR']),group_var='SK_ID_CURR',df_name='bureau')
bureau_agg.head()

bureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')
bureau_balance_counts.head()

bureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts,right_index=True, left_on='SK_ID_BUREAU',how='outer)

bureau_by_loan = burea[[''SK_ID_BUREAU','SK_ID_CURR']].merge(bureau_by_loan, on='SK_ID_BUREAU',how='left')

bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns=['SK_ID_BUREAU']),group_var='SK_ID_BUREAU',df_name='client')


print('Original Number of Features: ',len(original_features))

train = trian.merge(bureau_counts,on='SK_ID_CURR',how='left')

train = train.merge(bureau_agg,on='SK_ID_CURR',how='left')

train = t rain.merge(bureau_balance_by_client,on='SK_ID_BUREAU',how='left')


def missing_values_table(df):
    mis_val = df.isnull().sum()

    mis_val_percent = 100 * df.isnull().sum() / len(df)

    mis_val_table = pd.concat([mis_val,mis_val_percent],axis=1)

    mis_val_table_ren_columns = mis_val_table.rename(columns={0:'Missing Values',1:'% of Total Values'})

    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:,1] != 0].sort_values('% of Total Values', ascending =False).round(1)


    print('Your selected dataframe has" + str(df.shape[1]) + 'columns.\n'
    "There are" + str(mis_val_table_ren_columns.shape[0]) + "columns taht have missing values.")

    return mis_val_table_ren_columns

missing_train = missing_values_table(train)
missing_train.head(10)


missing_train_vars = list(missing_train.index[missing_train['% of Total Values'] > 90])

missing_train_vars = list(missing_train.index[missing_train['% of Total Values'] > 90])

len(missing_train_vars)


test = pd.read_csv('../input/application_test.csv')

test = test.merge(bureau_counts,on='SK_ID_BUREAU',how='left')
test = test.merge(bureau_agg,on='SK_ID_BUREAU',how='left')

test = test.merge(bureau_valance_by_client,on='SK_ID_CURR',how='left')

print('Shape of Testing data:',test.shape)

train_labels = train['TARGET']

train,test = train.align(test,join='inner',axis=1)

train['TARGET'] = train_labels

print('Testing Data Shape:', train.shape)
print('Testing Data Shape: ', test.shape)


missing_test = missing_values_table(test)
missing_test.head(10)


missing_test_vars = list(missing_Test.index[missing_test['% of Total Values'] > 90])

len(missing_test_vars)

missing_columns = list(set(missing_test_vars + missing_train_vars))

train = train.drop(columns = missing_columns)
test = test.drop(columns = missing_columns)

train.to_csv('train_bureau_raw.csv', index = False)
test.to_csv('test_bureau_raw.csv', index = False)

threshold = 0.8

above_threshold_vars = {}

for col in corrs:
    above_threshold_vars[col] = list(corrs.index[corrs[col] > threshold])

import lightgbm as lgb
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import LabelEncoder

